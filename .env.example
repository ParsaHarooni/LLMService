# LLM Provider Configuration
LLM_PROVIDER=openai  # Options: openai, deepseek, local

# OpenAI Configuration
OPENAI_API_KEY=your-api-key-here
OPENAI_MODEL=gpt-3.5-turbo

# Deepseek Configuration (if using Deepseek)
DEEPSEEK_API_KEY=your-deepseek-api-key
DEEPSEEK_MODEL=deepseek-chat

# Local Model Configuration (if using local model)
LOCAL_MODEL_PATH=/path/to/your/local/model 